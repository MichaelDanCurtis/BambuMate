---
phase: 07-auto-tuning-refinement
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src-tauri/src/history/mod.rs
  - src-tauri/src/history/types.rs
  - src-tauri/src/history/store.rs
  - src-tauri/src/profile/writer.rs
  - src-tauri/src/lib.rs
autonomous: true

must_haves:
  truths:
    - "User can see history of past analysis sessions for each profile"
    - "Profile backups are created before any modification"
    - "Applied changes are tracked with before/after values"
  artifacts:
    - path: "src-tauri/src/history/mod.rs"
      provides: "History module exports"
    - path: "src-tauri/src/history/types.rs"
      provides: "AppliedChange, SessionSummary, SessionDetail types"
      exports: ["AppliedChange", "SessionSummary", "SessionDetail"]
    - path: "src-tauri/src/history/store.rs"
      provides: "RefinementHistory SQLite store"
      exports: ["RefinementHistory"]
    - path: "src-tauri/src/profile/writer.rs"
      provides: "backup_profile function"
      contains: "pub fn backup_profile"
  key_links:
    - from: "src-tauri/src/history/store.rs"
      to: "rusqlite"
      via: "Connection::open"
      pattern: "Connection::open"
    - from: "src-tauri/src/profile/writer.rs"
      to: "std::fs"
      via: "fs::copy for backup"
      pattern: "fs::copy"
---

<objective>
Create the backend foundation for refinement history: SQLite persistence for analysis sessions, backup_profile() function for pre-modification snapshots, and types for tracking applied changes.

Purpose: This foundation enables the auto-apply workflow. Before any profile modification, a backup is created. Every analysis session is recorded so users can see their refinement history and revert changes.

Output: history/ module with SQLite store, backup_profile() in writer.rs, ready for Plan 02 to wire commands.
</objective>

<execution_context>
@/Users/michaelcurtis/.claude/get-shit-done/workflows/execute-plan.md
@/Users/michaelcurtis/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-auto-tuning-refinement/07-RESEARCH.md
@src-tauri/src/profile/writer.rs
@src-tauri/src/scraper/cache.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create history types and SQLite store</name>
  <files>
    src-tauri/src/history/mod.rs
    src-tauri/src/history/types.rs
    src-tauri/src/history/store.rs
  </files>
  <action>
Create the history module following the existing scraper/cache.rs SQLite pattern:

**types.rs:**
```rust
use serde::{Deserialize, Serialize};

/// A recorded change to a profile parameter.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AppliedChange {
    pub parameter: String,
    pub old_value: f32,
    pub new_value: f32,
}

/// Summary of a refinement session for list views.
#[derive(Debug, Clone, Serialize)]
pub struct SessionSummary {
    pub id: i64,
    pub created_at: String,
    pub was_applied: bool,
}

/// Full details of a refinement session.
#[derive(Debug, Clone, Serialize)]
pub struct SessionDetail {
    pub id: i64,
    pub profile_path: String,
    pub created_at: String,
    pub analysis_json: String,
    pub applied_changes: Option<Vec<AppliedChange>>,
    pub backup_path: Option<String>,
}
```

**store.rs:**
```rust
use std::path::Path;
use rusqlite::{Connection, params};
use super::types::{AppliedChange, SessionSummary, SessionDetail};

/// SQLite store for refinement history.
pub struct RefinementHistory {
    conn: Connection,
}

impl RefinementHistory {
    /// Create or open the history database.
    /// The db_path is the full path to the SQLite file.
    /// Typically called with: app.path().app_data_dir()?.join("refinement_history.db")
    pub fn new(db_path: &Path) -> Result<Self, String> {
        // Ensure parent directory exists
        if let Some(parent) = db_path.parent() {
            std::fs::create_dir_all(parent)
                .map_err(|e| format!("Failed to create data dir: {}", e))?;
        }

        let conn = Connection::open(db_path)
            .map_err(|e| format!("Failed to open history db: {}", e))?;

        conn.execute(
            "CREATE TABLE IF NOT EXISTS refinement_sessions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                profile_path TEXT NOT NULL,
                created_at TEXT NOT NULL DEFAULT (datetime('now')),
                image_base64 TEXT,
                analysis_json TEXT NOT NULL,
                applied_changes_json TEXT,
                backup_path TEXT
            )",
            [],
        ).map_err(|e| format!("Failed to create table: {}", e))?;

        // Create indexes for common queries
        conn.execute(
            "CREATE INDEX IF NOT EXISTS idx_sessions_profile ON refinement_sessions(profile_path)",
            [],
        ).map_err(|e| format!("Failed to create profile index: {}", e))?;

        conn.execute(
            "CREATE INDEX IF NOT EXISTS idx_sessions_created ON refinement_sessions(created_at DESC)",
            [],
        ).map_err(|e| format!("Failed to create date index: {}", e))?;

        Ok(Self { conn })
    }

    /// Record a new analysis session. Returns the session ID.
    pub fn record_analysis(
        &self,
        profile_path: &str,
        image_base64: Option<&str>,
        analysis_json: &str,
    ) -> Result<i64, String> {
        self.conn.execute(
            "INSERT INTO refinement_sessions (profile_path, image_base64, analysis_json)
             VALUES (?1, ?2, ?3)",
            params![profile_path, image_base64, analysis_json],
        ).map_err(|e| format!("Failed to insert session: {}", e))?;

        Ok(self.conn.last_insert_rowid())
    }

    /// Update a session after changes are applied.
    pub fn record_apply(
        &self,
        session_id: i64,
        changes: &[AppliedChange],
        backup_path: &str,
    ) -> Result<(), String> {
        let changes_json = serde_json::to_string(changes)
            .map_err(|e| format!("Failed to serialize changes: {}", e))?;

        self.conn.execute(
            "UPDATE refinement_sessions
             SET applied_changes_json = ?1, backup_path = ?2
             WHERE id = ?3",
            params![changes_json, backup_path, session_id],
        ).map_err(|e| format!("Failed to update session: {}", e))?;

        Ok(())
    }

    /// List all sessions for a profile, newest first.
    pub fn list_sessions(&self, profile_path: &str) -> Result<Vec<SessionSummary>, String> {
        let mut stmt = self.conn.prepare(
            "SELECT id, created_at, applied_changes_json IS NOT NULL as was_applied
             FROM refinement_sessions
             WHERE profile_path = ?1
             ORDER BY created_at DESC"
        ).map_err(|e| format!("Failed to prepare query: {}", e))?;

        let rows = stmt.query_map(params![profile_path], |row| {
            Ok(SessionSummary {
                id: row.get(0)?,
                created_at: row.get(1)?,
                was_applied: row.get(2)?,
            })
        }).map_err(|e| format!("Failed to query sessions: {}", e))?;

        rows.collect::<Result<Vec<_>, _>>()
            .map_err(|e| format!("Failed to collect sessions: {}", e))
    }

    /// Get full details of a session.
    pub fn get_session(&self, session_id: i64) -> Result<SessionDetail, String> {
        self.conn.query_row(
            "SELECT id, profile_path, created_at, analysis_json, applied_changes_json, backup_path
             FROM refinement_sessions WHERE id = ?1",
            params![session_id],
            |row| {
                let changes_json: Option<String> = row.get(4)?;
                let applied_changes = changes_json.and_then(|json| {
                    serde_json::from_str(&json).ok()
                });

                Ok(SessionDetail {
                    id: row.get(0)?,
                    profile_path: row.get(1)?,
                    created_at: row.get(2)?,
                    analysis_json: row.get(3)?,
                    applied_changes,
                    backup_path: row.get(5)?,
                })
            },
        ).map_err(|e| format!("Session not found: {}", e))
    }
}
```

Note: The store.new() takes a db_path parameter. Callers (in Plan 02 commands) will construct the path using Tauri's app.path().app_data_dir() and join "refinement_history.db". The store itself only needs the path - it does not depend on Tauri.

**mod.rs:**
```rust
mod types;
mod store;

pub use types::*;
pub use store::RefinementHistory;
```
  </action>
  <verify>
`cargo check -p bambumate` passes with no errors.
`cargo test -p bambumate -- history` passes (add basic tests for store operations).
  </verify>
  <done>
history module exists with types (AppliedChange, SessionSummary, SessionDetail) and RefinementHistory store implementing record_analysis, record_apply, list_sessions, get_session.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add backup_profile function to writer</name>
  <files>src-tauri/src/profile/writer.rs</files>
  <action>
Add a backup_profile() function to the existing writer.rs:

```rust
use chrono::Utc;

/// Create a timestamped backup of a profile before modification.
/// Returns the backup path on success.
pub fn backup_profile(profile_path: &Path) -> Result<PathBuf> {
    let timestamp = Utc::now().format("%Y%m%d_%H%M%S");
    let stem = profile_path.file_stem()
        .and_then(|s| s.to_str())
        .ok_or_else(|| anyhow::anyhow!("Invalid profile path"))?;

    // Create .backups directory alongside profile
    let backup_dir = profile_path.parent()
        .ok_or_else(|| anyhow::anyhow!("No parent directory"))?
        .join(".backups");
    std::fs::create_dir_all(&backup_dir)?;

    let backup_name = format!("{}_{}.json", stem, timestamp);
    let backup_path = backup_dir.join(backup_name);

    std::fs::copy(profile_path, &backup_path)?;

    info!("Created backup at {:?}", backup_path);
    Ok(backup_path)
}
```

Add chrono to Cargo.toml if not present (check first - likely already there from scraper).

Also add a restore_from_backup function:
```rust
/// Restore a profile from a backup file.
pub fn restore_from_backup(backup_path: &Path, profile_path: &Path) -> Result<()> {
    let backup_profile = super::reader::read_profile(backup_path)?;
    write_profile_atomic(&backup_profile, profile_path)?;
    info!("Restored profile from {:?}", backup_path);
    Ok(())
}
```
  </action>
  <verify>
`cargo check -p bambumate` passes.
`cargo test -p bambumate -- profile::writer` includes a test for backup_profile.
  </verify>
  <done>
backup_profile() creates timestamped backups in .backups/ subdirectory.
restore_from_backup() can restore a profile from backup.
  </done>
</task>

<task type="auto">
  <name>Task 3: Wire history module to lib.rs</name>
  <files>src-tauri/src/lib.rs</files>
  <action>
Add the history module declaration to lib.rs:

```rust
pub mod history;
```

Add re-exports if following existing pattern:
```rust
pub use history::{AppliedChange, RefinementHistory, SessionDetail, SessionSummary};
```

Verify it builds cleanly with all existing modules.
  </action>
  <verify>
`cargo check -p bambumate` passes with history module integrated.
`cargo build -p bambumate` completes successfully.
  </verify>
  <done>
history module is part of the crate, types and store accessible from other modules.
  </done>
</task>

</tasks>

<verification>
1. `cargo check -p bambumate` - no errors
2. `cargo test -p bambumate` - all existing tests pass, new history tests pass
3. history module exports: AppliedChange, SessionSummary, SessionDetail, RefinementHistory
4. writer.rs exports: backup_profile, restore_from_backup
</verification>

<success_criteria>
- RefinementHistory can create, query, and update refinement sessions
- backup_profile() creates timestamped copy in .backups/ directory
- All existing 85+ tests continue to pass
- New history tests verify CRUD operations
</success_criteria>

<output>
After completion, create `.planning/phases/07-auto-tuning-refinement/07-01-SUMMARY.md`
</output>
